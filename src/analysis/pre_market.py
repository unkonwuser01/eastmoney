"""
Pre-Market Analyst - ä¸“ä¸šçº§ç›˜å‰æƒ…æŠ¥ç³»ç»Ÿ
=====================================
æ¨¡æ‹Ÿä¸“ä¸šåŸºé‡‘ç»ç†å›¢é˜Ÿçš„ç›˜å‰ç ”ç©¶æµç¨‹ï¼š
1. å…¨çƒå®è§‚ä¿¡å·æ”¶é›†ï¼ˆéš”å¤œç¾è‚¡ã€A50ã€æ±‡ç‡ï¼‰
2. åŒ—å‘èµ„é‡‘ä¸è¡Œä¸šèµ„é‡‘æµå‘
3. é‡ä»“è‚¡æ·±åº¦ç›‘æ§ï¼ˆå…¬å‘Šã€ç ”æŠ¥ã€é£é™©ï¼‰
4. è¡Œä¸šæ”¿ç­–ä¸äº§ä¸šé“¾åŠ¨æ€
5. ä¿¡å·æ±‡æ€»ä¸äº¤å‰éªŒè¯
"""

import json
import sys
import os
from typing import List, Dict, Optional
from datetime import datetime

# Add project root to sys.path
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from config.settings import FUNDS_FILE
from src.data_sources.akshare_api import (
    get_fund_holdings,
    get_market_indices,
    get_global_macro_summary,
    get_northbound_flow,
    get_industry_capital_flow,
    get_sector_performance,
    get_concept_board_performance,
    get_stock_realtime_quote
)
from src.data_sources.web_search import WebSearch
from src.llm.client import get_llm_client
from src.llm.prompts import PRE_MARKET_PROMPT_TEMPLATE


class PreMarketAnalyst:
    """
    ä¸“ä¸šçº§ç›˜å‰åˆ†æå¸ˆ
    æ¨¡æ‹ŸåŸºé‡‘ç»ç†å›¢é˜Ÿçš„æ™¨ä¼šç ”ç©¶æµç¨‹
    """
    
    def __init__(self):
        self.web_search = WebSearch()
        self.llm = get_llm_client()
        self.funds = self._load_funds()
        self.today = datetime.now().strftime("%Y-%m-%d")
        self.sources = []  # æ•°æ®æ¥æºè¿½è¸ª
        
    def _load_funds(self) -> List[Dict]:
        if not os.path.exists(FUNDS_FILE):
            print(f"Warning: Funds file not found at {FUNDS_FILE}")
            return []
        with open(FUNDS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)

    # =========================================================================
    # Source Tracking Utilities
    # =========================================================================
    
    def _reset_sources(self):
        """æ¯æ¬¡åˆ†ææ–°åŸºé‡‘å‰é‡ç½®æ¥æºåˆ—è¡¨"""
        self.sources = []
    
    def _add_source(self, category: str, title: str, url: str = None, source_name: str = None):
        """æ·»åŠ ä¸€ä¸ªæ•°æ®æ¥æº"""
        source_entry = {
            'category': category,  # e.g., 'å®è§‚æ–°é—»', 'æŒä»“å…¬å‘Š', 'ç ”æŠ¥', 'æ”¿ç­–'
            'title': title[:100] if title else 'N/A',
            'url': url,
            'source': source_name
        }
        # é¿å…é‡å¤
        if not any(s['title'] == source_entry['title'] and s['url'] == source_entry['url'] for s in self.sources):
            self.sources.append(source_entry)
    
    def _format_sources(self) -> str:
        """æ ¼å¼åŒ–æ•°æ®æ¥æºä¸ºæŠ¥å‘Šé™„å½•"""
        if not self.sources:
            return ""
        
        output = []
        output.append("\n\n---")
        output.append("\n## ğŸ“š æ•°æ®æ¥æº (Sources Used in This Report)")
        
        # æŒ‰ç±»åˆ«åˆ†ç»„
        categories = {}
        for source in self.sources:
            cat = source['category']
            if cat not in categories:
                categories[cat] = []
            categories[cat].append(source)
        
        # æ ¼å¼åŒ–è¾“å‡º
        for cat, items in categories.items():
            output.append(f"\n### {cat}")
            for i, item in enumerate(items, 1):
                title = item['title']
                url = item['url']
                source_name = item.get('source', '')
                
                if url:
                    output.append(f"{i}. [{title}]({url})")
                else:
                    source_suffix = f" - {source_name}" if source_name else ""
                    output.append(f"{i}. {title}{source_suffix}")
        
        # å›ºå®šæ•°æ®æºè¯´æ˜
        output.append("\n### ğŸ“Š å¸‚åœºæ•°æ®æ¥æº")
        output.append("- AkShare: Aè‚¡æŒ‡æ•°ã€åŒ—å‘èµ„é‡‘ã€è¡Œä¸šèµ„é‡‘æµå‘")
        output.append("- ä¸œæ–¹è´¢å¯Œ: åŸºé‡‘æŒä»“æ•°æ®")
        output.append("- Tavily Search API: å®æ—¶æ–°é—»ä¸ç ”æŠ¥æœç´¢")
        
        return "\n".join(output)

    # =========================================================================
    # Layer 1: å…¨çƒå®è§‚æ•°æ®æ”¶é›†
    # =========================================================================
    
    def collect_global_macro(self) -> str:
        """æ”¶é›†å…¨çƒå®è§‚æ•°æ®ï¼šç¾è‚¡ã€A50ã€æ±‡ç‡"""
        print("  ğŸ“¡ æ”¶é›†å…¨çƒå®è§‚ä¿¡å·...")
        
        macro_data = get_global_macro_summary()
        
        # æ ¼å¼åŒ–è¾“å‡º
        output = []
        
        # ç¾è‚¡å¸‚åœº
        if macro_data.get("ç¾è‚¡å¸‚åœº"):
            output.append("**éš”å¤œç¾è‚¡:**")
            for name, data in macro_data["ç¾è‚¡å¸‚åœº"].items():
                if isinstance(data, dict):
                    price = data.get('æœ€æ–°ä»·', data.get('æ”¶ç›˜', 'N/A'))
                    change = data.get('æ¶¨è·Œå¹…', data.get('æ¶¨è·Œ', 'N/A'))
                    output.append(f"- {name}: {price} ({change})")
        
        # A50æœŸè´§ / äºšå¤ªæŒ‡æ•°
        if macro_data.get("A50æœŸè´§"):
            a50_data = macro_data["A50æœŸè´§"]
            if isinstance(a50_data, dict):
                # æ£€æŸ¥æ˜¯å¦æ˜¯æ—§æ ¼å¼ï¼ˆç›´æ¥æœ‰æ”¶ç›˜å­—æ®µï¼‰è¿˜æ˜¯æ–°æ ¼å¼ï¼ˆå¤šä¸ªæŒ‡æ•°ï¼‰
                if 'è¯´æ˜' in a50_data:
                    output.append(f"\n**äºšå¤ªå¸‚åœº:** {a50_data.get('è¯´æ˜', 'N/A')}")
                elif 'æ”¶ç›˜' in a50_data:
                    # æ—§æ ¼å¼
                    output.append("\n**å¯Œæ—¶A50æœŸè´§:**")
                    output.append(f"- æœ€æ–°: {a50_data.get('æ”¶ç›˜', 'N/A')}")
                    if 'å¤œç›˜æ¶¨è·Œå¹…' in a50_data:
                        output.append(f"- å¤œç›˜æ¶¨è·Œ: {a50_data['å¤œç›˜æ¶¨è·Œå¹…']}%")
                else:
                    # æ–°æ ¼å¼ï¼šå¤šä¸ªäºšå¤ªæŒ‡æ•°
                    output.append("\n**äºšå¤ªå¸‚åœºæŒ‡æ•°:**")
                    for idx_name, idx_data in a50_data.items():
                        if isinstance(idx_data, dict):
                            price = idx_data.get('æœ€æ–°ä»·', 'N/A')
                            change = idx_data.get('æ¶¨è·Œå¹…', 'N/A')
                            if change != 'N/A':
                                change = f"{change}%" if not str(change).endswith('%') else change
                            output.append(f"- {idx_name}: {price} ({change})")
        
        # æ±‡ç‡
        if macro_data.get("æ±‡ç‡"):
            output.append("\n**æ±‡ç‡:**")
            for name, data in macro_data["æ±‡ç‡"].items():
                if isinstance(data, dict):
                    rate = data.get('ä¹°å…¥ä»·', data.get('æœ€æ–°ä»·', 'N/A'))
                    output.append(f"- {name}: {rate}")
        
        # è¡¥å……ï¼šæœç´¢å®è§‚äº‹ä»¶æ–°é—»
        print("  ğŸ“¡ æœç´¢éš”å¤œå®è§‚äº‹ä»¶...")
        macro_news = self.web_search.search_macro_events(max_results=3)
        if macro_news:
            output.append("\n**éš”å¤œé‡è¦äº‹ä»¶:**")
            for news in macro_news:
                title = news.get('title', news.get('content', '')[:100])
                output.append(f"- {title}")
                # è¿½è¸ªæ¥æº
                self._add_source(
                    category="ğŸŒ å®è§‚æ–°é—»",
                    title=title,
                    url=news.get('url'),
                    source_name=news.get('source', 'Web Search')
                )
        
        return "\n".join(output) if output else "å…¨çƒå®è§‚æ•°æ®æš‚æ—¶æ— æ³•è·å–"

    # =========================================================================
    # Layer 2: èµ„é‡‘æµå‘åˆ†æ
    # =========================================================================
    
    def collect_capital_flow(self, fund_focus: List[str]) -> tuple:
        """æ”¶é›†åŒ—å‘èµ„é‡‘å’Œè¡Œä¸šèµ„é‡‘æµå‘"""
        print("  ğŸ’° åˆ†æèµ„é‡‘æµå‘...")
        
        # åŒ—å‘èµ„é‡‘
        northbound = get_northbound_flow()
        nb_output = []
        if northbound:
            if northbound.get('æœ€æ–°å‡€æµå…¥'):
                latest = northbound['æœ€æ–°å‡€æµå…¥']
                nb_output.append(f"**æœ€æ–°åŒ—å‘èµ„é‡‘:** {latest}")
            if northbound.get('5æ—¥ç´¯è®¡å‡€æµå…¥'):
                nb_output.append(f"**5æ—¥ç´¯è®¡:** {northbound['5æ—¥ç´¯è®¡å‡€æµå…¥']}äº¿")
        
        northbound_str = "\n".join(nb_output) if nb_output else "åŒ—å‘èµ„é‡‘æ•°æ®æš‚æ— "
        
        # è¡Œä¸šèµ„é‡‘æµå‘
        sector_flow = get_industry_capital_flow()
        sector_output = []
        if sector_flow.get('è¡Œä¸šèµ„é‡‘æµå‘Top10'):
            sector_output.append("**è¡Œä¸šèµ„é‡‘æµå‘Top10:**")
            for item in sector_flow['è¡Œä¸šèµ„é‡‘æµå‘Top10'][:5]:
                if isinstance(item, dict):
                    name = item.get('åç§°', 'N/A')
                    flow = item.get('ä»Šæ—¥ä¸»åŠ›å‡€æµå…¥', item.get('ä¸»åŠ›å‡€æµå…¥', 'N/A'))
                    sector_output.append(f"- {name}: {flow}")
        
        # æŸ¥æ‰¾åŸºé‡‘å…³æ³¨çš„è¡Œä¸š
        for focus in fund_focus[:2]:
            industry_data = get_industry_capital_flow(focus)
            if industry_data and isinstance(industry_data, dict) and 'åç§°' in industry_data:
                sector_output.append(f"\n**{focus}æ¿å—èµ„é‡‘:** {industry_data}")
        
        sector_str = "\n".join(sector_output) if sector_output else "è¡Œä¸šèµ„é‡‘æµå‘æ•°æ®æš‚æ— "
        
        return northbound_str, sector_str

    # =========================================================================
    # Layer 3: æŒä»“è‚¡æ·±åº¦åˆ†æ
    # =========================================================================
    
    def collect_holdings_data(self, fund_code: str) -> tuple:
        """æ”¶é›†æŒä»“æ•°æ®å’Œæ·±åº¦ä¿¡æ¯"""
        print("  ğŸ“Š è·å–åŸºé‡‘æŒä»“...")
        
        holdings_df = get_fund_holdings(fund_code)
        
        if holdings_df.empty:
            return "æŒä»“æ•°æ®æš‚æ— ", "æŒä»“æ·±åº¦ä¿¡æ¯æš‚æ— ", []
        
        # æå–æŒä»“åŸºæœ¬ä¿¡æ¯
        holdings_output = []
        name_col = next((col for col in holdings_df.columns if 'åç§°' in col), None)
        code_col = next((col for col in holdings_df.columns if 'ä»£ç ' in col), None)
        ratio_col = next((col for col in holdings_df.columns if 'æ¯”ä¾‹' in col), None)
        
        # è·å–æœ€æ–°ä¸€æœŸæŒä»“ï¼ˆé€šå¸¸æŒ‰å­£åº¦ï¼‰
        if 'å­£åº¦' in holdings_df.columns:
            latest_quarter = holdings_df['å­£åº¦'].iloc[0]
            holdings_df = holdings_df[holdings_df['å­£åº¦'] == latest_quarter]
        
        top_holdings = holdings_df.head(10)
        holdings_list = []
        
        holdings_output.append(f"**æœ€æ–°æŒä»“ï¼ˆTop 10ï¼‰:**")
        for _, row in top_holdings.iterrows():
            name = row.get(name_col, 'N/A') if name_col else 'N/A'
            code = row.get(code_col, '') if code_col else ''
            ratio = row.get(ratio_col, 'N/A') if ratio_col else 'N/A'
            holdings_output.append(f"- {name}({code}): {ratio}%")
            if name != 'N/A':
                holdings_list.append({'name': name, 'code': str(code)})
        
        holdings_str = "\n".join(holdings_output)
        

        # æ·±åº¦åˆ†æTop 5æŒä»“
        print("  ğŸ” æ·±åº¦åˆ†æé‡ä»“è‚¡...")
        deep_dive_output = []
        
        for holding in holdings_list[:5]:
            stock_name = holding['name']
            stock_code = holding['code']
            
            deep_dive_output.append(f"\n**{stock_name}:**")
            
            # åˆ†å±‚æœç´¢
            search_results = self.web_search.comprehensive_stock_search(stock_name)
            
            # å…¬å‘Š
            if search_results.get('announcements'):
                deep_dive_output.append("  *å…¬å‘Š:*")
                for ann in search_results['announcements'][:2]:
                    title = ann.get('title', ann.get('content', ''))[:80]
                    deep_dive_output.append(f"    - {title}")
                    # è¿½è¸ªæ¥æº
                    self._add_source(
                        category="ğŸ“¢ å…¬å¸å…¬å‘Š",
                        title=f"[{stock_name}] {title}",
                        url=ann.get('url'),
                        source_name=ann.get('source', 'Web Search')
                    )
            
            # ç ”æŠ¥
            if search_results.get('analyst_reports'):
                deep_dive_output.append("  *ç ”æŠ¥/è¯„çº§:*")
                for report in search_results['analyst_reports'][:2]:
                    title = report.get('title', report.get('content', ''))[:80]
                    deep_dive_output.append(f"    - {title}")
                    # è¿½è¸ªæ¥æº
                    self._add_source(
                        category="ğŸ“Š ç ”ç©¶æŠ¥å‘Š",
                        title=f"[{stock_name}] {title}",
                        url=report.get('url'),
                        source_name=report.get('source', 'Web Search')
                    )
            
            # é£é™©
            if search_results.get('risk_events'):
                deep_dive_output.append("  *é£é™©ç›‘æ§:*")
                for risk in search_results['risk_events'][:1]:
                    title = risk.get('title', risk.get('content', ''))[:80]
                    deep_dive_output.append(f"    - {title}")
                    # è¿½è¸ªæ¥æº
                    self._add_source(
                        category="âš ï¸ é£é™©äº‹ä»¶",
                        title=f"[{stock_name}] {title}",
                        url=risk.get('url'),
                        source_name=risk.get('source', 'Web Search')
                    )
        
        deep_dive_str = "\n".join(deep_dive_output) if deep_dive_output else "æŒä»“æ·±åº¦åˆ†ææš‚æ— "
        
        return holdings_str, deep_dive_str, holdings_list

    # =========================================================================
    # Layer 4: è¡Œä¸šæ”¿ç­–åˆ†æ
    # =========================================================================
    
    def collect_policy_news(self, fund_focus: List[str]) -> str:
        """æ”¶é›†è¡Œä¸šæ”¿ç­–æ–°é—»"""
        print("  ğŸ“° æœç´¢è¡Œä¸šæ”¿ç­–...")
        
        policy_output = []
        
        for industry in fund_focus[:3]:
            print(f"    - æœç´¢ {industry} æ”¿ç­–...")
            news = self.web_search.search_policy_news(industry, max_results=2)
            
            if news:
                policy_output.append(f"**{industry}:**")
                for item in news:
                    title = item.get('title', item.get('content', ''))[:100]
                    confidence = item.get('confidence', 'MEDIUM')
                    policy_output.append(f"- [{confidence}] {title}")
                    # è¿½è¸ªæ¥æº
                    self._add_source(
                        category="ğŸ“œ è¡Œä¸šæ”¿ç­–",
                        title=f"[{industry}] {title}",
                        url=item.get('url'),
                        source_name=item.get('source', 'Web Search')
                    )
                policy_output.append("")
        
        return "\n".join(policy_output) if policy_output else "æš‚æ— ç›¸å…³è¡Œä¸šæ”¿ç­–æ–°é—»"

    # =========================================================================
    # ä¸»åˆ†ææµç¨‹
    # =========================================================================
    
    def analyze_fund(self, fund: Dict) -> str:
        """
        å•åªåŸºé‡‘çš„å®Œæ•´ç›˜å‰åˆ†ææµç¨‹
        """
        fund_code = fund.get("code")
        fund_name = fund.get("name")
        fund_style = fund.get("style", "æ··åˆå‹")
        fund_focus = fund.get("focus", [])
        
        print(f"\n{'='*60}")
        print(f"ğŸ” åˆ†æåŸºé‡‘: {fund_name} ({fund_code})")
        print(f"{'='*60}")
        
        # é‡ç½®æ¥æºè¿½è¸ª
        self._reset_sources()
        
        # Step 1: å…¨çƒå®è§‚
        global_macro = self.collect_global_macro()
        
        # Step 2: èµ„é‡‘æµå‘
        northbound_data, sector_flow_data = self.collect_capital_flow(fund_focus)
        
        # Step 3: æŒä»“åˆ†æ
        holdings_data, holdings_deep_dive, holdings_list = self.collect_holdings_data(fund_code)
        
        # Step 4: è¡Œä¸šæ”¿ç­–
        policy_news = self.collect_policy_news(fund_focus)
        
        print(" æ”¶é›†åˆ°çš„è¡Œä¸šæ”¿ç­–ä¿¡æ¯ï¼š", policy_news)

        # Step 5: æ„å»ºPromptå¹¶è°ƒç”¨LLM
        print("  ğŸ¤– AI ç»¼åˆç ”åˆ¤ä¸­...")
        
        prompt = PRE_MARKET_PROMPT_TEMPLATE.format(
            fund_name=fund_name,
            fund_code=fund_code,
            fund_style=fund_style,
            fund_focus=", ".join(fund_focus) if fund_focus else "ç»¼åˆ",
            global_macro_data=global_macro,
            northbound_data=northbound_data,
            sector_flow_data=sector_flow_data,
            holdings_data=holdings_data,
            holdings_deep_dive=holdings_deep_dive,
            policy_news=policy_news,
            report_date=self.today  # ä¼ å…¥å®é™…æ—¥æœŸ
        )
        
        # è°ƒç”¨LLMç”ŸæˆæŠ¥å‘Š
        report = self.llm.generate_content(prompt)
        
        # é™„åŠ æ•°æ®æ¥æº
        sources_section = self._format_sources()
        if sources_section:
            report = report + sources_section
        
        print(f"  ğŸ“š æ”¶é›†åˆ° {len(self.sources)} ä¸ªæ•°æ®æ¥æº")
        print("  âœ… åˆ†æå®Œæˆ")
        return report

    def run_all(self) -> str:
        """
        è¿è¡Œæ‰€æœ‰åŸºé‡‘çš„ç›˜å‰åˆ†æ
        """
        print(f"\n{'#'*60}")
        print(f"# ç›˜å‰æƒ…æŠ¥ç³»ç»Ÿå¯åŠ¨ - {self.today}")
        print(f"# å¾…åˆ†æåŸºé‡‘æ•°é‡: {len(self.funds)}")
        print(f"{'#'*60}")
        
        reports = []
        for fund in self.funds:
            try:
                report = self.analyze_fund(fund)
                if report:
                    reports.append(report)
            except Exception as e:
                print(f"  âŒ åˆ†æå¤±è´¥: {e}")
                reports.append(f"## {fund.get('name')} åˆ†æå¤±è´¥\né”™è¯¯: {str(e)}")
        
        return "\n\n---\n\n".join(reports)

    def run_one(self, fund_code: str) -> str:
        """
        è¿è¡ŒæŒ‡å®šåŸºé‡‘çš„ç›˜å‰åˆ†æ
        """
        target_fund = next((f for f in self.funds if f["code"] == fund_code), None)
        if not target_fund:
            return f"Error: Fund with code {fund_code} not found in configuration."
        
        return self.analyze_fund(target_fund)


if __name__ == "__main__":
    analyst = PreMarketAnalyst()
    print(analyst.run_all())
